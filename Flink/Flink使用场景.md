# Flink使用场景

## Flink的主要特点

* 支持流式数据处理
* 支持批数据处理
* 复杂的状态管理
* event-time 处理语义
* exactly-once状态一致性保证 

## 场景一：事件驱动程序（Event-driven）

### 什么是事件驱动程序?

事件驱动程序，是有状态的程序。从一个或者多个事件流中，接受事件，并且通过触发计算，和进来的事件进行交互，产生状态更新或外部操作。

事件驱动程序，是对计算和数据存储层分开，这一传统设计方式的提升。在传统架构中，程序从远程的事务性数据库中读取数据，并且向其中存储数据。

### Flink是怎样支持事件驱动程序的?
事件驱动程序性能，被流式处理器，处理时间和状态的能力限制。
Flink的许多优秀的特点，都是围绕时间和状态的处理，展开的。

* Flink提供了一系列的状态管理原语，可以管理超大量数据（太字节）的exactly-once一致性保证。
* Flink支持event-time，高度自定义的窗口逻辑（window logic），细粒度的（fine-grained）时间控制。

* Flink有一个包，能进行复杂事件处理（Complex Event Processing 、简称CEP），它检测数据流中的模式。
* Flink的另一个优秀特点是savepoint。一个savepoint是一个连续的状态镜像（image），这个镜像可以用来作为兼容程序的开始点。给定一个savepoint, 应用程序可以更新或者调整它的规模, 或者一个程序的多个版本，可以用来做 A/B 测试。

## 场景二：数据分析程序
流式数据分析，比批处理数据分析的优点，批处理过程中的一个环节失败了，整个过程要重新计算。
流式数据分析，有失败恢复机制。

### Flink是怎么支持数据分析程序的？
Flink有ANSI-兼容SQL接口，对于批式查询和流式查询，有相同的语义。 SQL查询，不管运行在静态的数据上，还是实时的事件流上，会计算出相同的结果。 支持丰富的用户自定义函数。Flink的DataStream API、 DataSet API 能提供更灵活的自定义，更低阶的控制。Flink的Gelly包，提供对大规模数据的图分析。 

## 场景三：数据管道程序
ETL（Extract-transform-load）是在存储系统间，转换和移动数据的常用方法。通常，ETL 任务是定时触发，从一个关系型数据库拷贝到分析型数据库，或者数据仓库。 
数据管道程序和ETL任务目的类似，最大的特点是，实时处理。
### Flink是怎么支持数据管道的？

Flink 提供了到各种存储系统的connectors，例如Kafka, Kinesis, Elasticsearch, JDBC。也类似Flume，有source和sink，source可以监控目录。
 




